{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cd .."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle as pkl\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "from src.utils.helpers import *\n",
    "from src.utils.eda_helpers import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV,StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, roc_auc_score, roc_curve, confusion_matrix, log_loss, f1_score, precision_recall_curve, make_scorer\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")  # To ignore any warnings \n",
    "\n",
    "seed = 123\n",
    "pd.options.display.max_rows = None "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load saved objects from 0.1-eda\n",
    "vect_cols = pkl.load(open(\"./models/vect_cols.pkl\",'rb'))\n",
    "tfidf_cols = pkl.load(open(\"./models/tfidf_cols.pkl\",'rb'))\n",
    "labelencoder = pkl.load(open(\"./models/labelencoder.pkl\",'rb'))\n",
    "\n",
    "labels_df = pd.read_csv('./data/output/labels_df.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "features_df_raw = pd.read_csv('./data/features.csv')\n",
    "features_df = features_df_raw.copy()\n",
    "labels_df = labels_df_raw.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "features_df.head(2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   trackID                   title  \\\n",
       "0     6654  Beside the Yellow Line   \n",
       "1     5883               Ooh Na Na   \n",
       "\n",
       "                                                tags  loudness    tempo  \\\n",
       "0  i, the, to, and, a, me, it, not, in, my, is, o...    -8.539  104.341   \n",
       "1  i, you, to, and, a, me, it, not, in, my, is, y...    -4.326  141.969   \n",
       "\n",
       "   time_signature  key  mode   duration     vect_1  ...  vect_139  vect_140  \\\n",
       "0             3.0  7.0   1.0  298.73587  44.462048  ...  0.000308  0.000302   \n",
       "1             3.0  6.0   0.0  236.09424  46.069761  ...  0.001751  0.001855   \n",
       "\n",
       "   vect_141  vect_142  vect_143  vect_144  vect_145  vect_146  vect_147  \\\n",
       "0  0.000302  0.000315  0.000297  0.000305  0.000266  0.000225  0.130826   \n",
       "1  0.001920  0.001950  0.001937  0.001912  0.001836  0.001740  0.148765   \n",
       "\n",
       "   vect_148  \n",
       "0  1.071914  \n",
       "1  0.882304  \n",
       "\n",
       "[2 rows x 157 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trackID</th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "      <th>loudness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>duration</th>\n",
       "      <th>vect_1</th>\n",
       "      <th>...</th>\n",
       "      <th>vect_139</th>\n",
       "      <th>vect_140</th>\n",
       "      <th>vect_141</th>\n",
       "      <th>vect_142</th>\n",
       "      <th>vect_143</th>\n",
       "      <th>vect_144</th>\n",
       "      <th>vect_145</th>\n",
       "      <th>vect_146</th>\n",
       "      <th>vect_147</th>\n",
       "      <th>vect_148</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6654</td>\n",
       "      <td>Beside the Yellow Line</td>\n",
       "      <td>i, the, to, and, a, me, it, not, in, my, is, o...</td>\n",
       "      <td>-8.539</td>\n",
       "      <td>104.341</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>298.73587</td>\n",
       "      <td>44.462048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.130826</td>\n",
       "      <td>1.071914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5883</td>\n",
       "      <td>Ooh Na Na</td>\n",
       "      <td>i, you, to, and, a, me, it, not, in, my, is, y...</td>\n",
       "      <td>-4.326</td>\n",
       "      <td>141.969</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>236.09424</td>\n",
       "      <td>46.069761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>0.001920</td>\n",
       "      <td>0.001950</td>\n",
       "      <td>0.001937</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.001836</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>0.148765</td>\n",
       "      <td>0.882304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 157 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "features_df.isnull().sum()/len(features_df)*100\n",
    "# some missing values. will impute later"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "trackID           0.000000\n",
       "title             0.086122\n",
       "tags              0.147638\n",
       "loudness          0.123031\n",
       "tempo             0.135335\n",
       "time_signature    0.110728\n",
       "key               0.184547\n",
       "mode              0.110728\n",
       "duration          0.110728\n",
       "vect_1            0.123031\n",
       "vect_2            0.098425\n",
       "vect_3            0.135335\n",
       "vect_4            0.147638\n",
       "vect_5            0.110728\n",
       "vect_6            0.147638\n",
       "vect_7            0.123031\n",
       "vect_8            0.098425\n",
       "vect_9            0.123031\n",
       "vect_10           0.123031\n",
       "vect_11           0.098425\n",
       "vect_12           0.159941\n",
       "vect_13           0.000000\n",
       "vect_14           0.000000\n",
       "vect_15           0.000000\n",
       "vect_16           0.000000\n",
       "vect_17           0.000000\n",
       "vect_18           0.000000\n",
       "vect_19           0.000000\n",
       "vect_20           0.000000\n",
       "vect_21           0.000000\n",
       "vect_22           0.000000\n",
       "vect_23           0.000000\n",
       "vect_24           0.000000\n",
       "vect_25           0.000000\n",
       "vect_26           0.000000\n",
       "vect_27           0.000000\n",
       "vect_28           0.000000\n",
       "vect_29           0.000000\n",
       "vect_30           0.000000\n",
       "vect_31           0.000000\n",
       "vect_32           0.024606\n",
       "vect_33           0.024606\n",
       "vect_34           0.049213\n",
       "vect_35           0.036909\n",
       "vect_36           0.012303\n",
       "vect_37           0.036909\n",
       "vect_38           0.024606\n",
       "vect_39           0.073819\n",
       "vect_40           0.061516\n",
       "vect_41           0.012303\n",
       "vect_42           0.000000\n",
       "vect_43           0.012303\n",
       "vect_44           0.024606\n",
       "vect_45           0.012303\n",
       "vect_46           0.000000\n",
       "vect_47           0.036909\n",
       "vect_48           0.049213\n",
       "vect_49           0.024606\n",
       "vect_50           0.036909\n",
       "vect_51           0.012303\n",
       "vect_52           0.024606\n",
       "vect_53           0.049213\n",
       "vect_54           0.024606\n",
       "vect_55           0.024606\n",
       "vect_56           0.000000\n",
       "vect_57           0.012303\n",
       "vect_58           0.024606\n",
       "vect_59           0.012303\n",
       "vect_60           0.024606\n",
       "vect_61           0.024606\n",
       "vect_62           0.049213\n",
       "vect_63           0.024606\n",
       "vect_64           0.024606\n",
       "vect_65           0.024606\n",
       "vect_66           0.024606\n",
       "vect_67           0.036909\n",
       "vect_68           0.012303\n",
       "vect_69           0.036909\n",
       "vect_70           0.024606\n",
       "vect_71           0.024606\n",
       "vect_72           0.000000\n",
       "vect_73           0.012303\n",
       "vect_74           0.024606\n",
       "vect_75           0.000000\n",
       "vect_76           0.012303\n",
       "vect_77           0.036909\n",
       "vect_78           0.036909\n",
       "vect_79           0.024606\n",
       "vect_80           0.000000\n",
       "vect_81           0.000000\n",
       "vect_82           0.012303\n",
       "vect_83           0.012303\n",
       "vect_84           0.012303\n",
       "vect_85           0.049213\n",
       "vect_86           0.012303\n",
       "vect_87           0.036909\n",
       "vect_88           0.000000\n",
       "vect_89           0.024606\n",
       "vect_90           0.012303\n",
       "vect_91           0.036909\n",
       "vect_92           0.012303\n",
       "vect_93           0.000000\n",
       "vect_94           0.000000\n",
       "vect_95           0.049213\n",
       "vect_96           0.024606\n",
       "vect_97           0.000000\n",
       "vect_98           0.024606\n",
       "vect_99           0.036909\n",
       "vect_100          0.024606\n",
       "vect_101          0.000000\n",
       "vect_102          0.000000\n",
       "vect_103          0.024606\n",
       "vect_104          0.012303\n",
       "vect_105          0.012303\n",
       "vect_106          0.024606\n",
       "vect_107          0.061516\n",
       "vect_108          0.049213\n",
       "vect_109          0.036909\n",
       "vect_110          0.024606\n",
       "vect_111          0.012303\n",
       "vect_112          0.024606\n",
       "vect_113          0.000000\n",
       "vect_114          0.036909\n",
       "vect_115          0.000000\n",
       "vect_116          0.012303\n",
       "vect_117          0.036909\n",
       "vect_118          0.012303\n",
       "vect_119          0.036909\n",
       "vect_120          0.012303\n",
       "vect_121          0.012303\n",
       "vect_122          0.024606\n",
       "vect_123          0.012303\n",
       "vect_124          0.000000\n",
       "vect_125          0.049213\n",
       "vect_126          0.036909\n",
       "vect_127          0.036909\n",
       "vect_128          0.012303\n",
       "vect_129          0.012303\n",
       "vect_130          0.024606\n",
       "vect_131          0.012303\n",
       "vect_132          0.024606\n",
       "vect_133          0.012303\n",
       "vect_134          0.012303\n",
       "vect_135          0.024606\n",
       "vect_136          0.012303\n",
       "vect_137          0.024606\n",
       "vect_138          0.036909\n",
       "vect_139          0.036909\n",
       "vect_140          0.012303\n",
       "vect_141          0.012303\n",
       "vect_142          0.024606\n",
       "vect_143          0.000000\n",
       "vect_144          0.000000\n",
       "vect_145          0.000000\n",
       "vect_146          0.000000\n",
       "vect_147          0.000000\n",
       "vect_148          0.000000\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "features_df.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8128 entries, 0 to 8127\n",
      "Columns: 157 entries, trackID to vect_148\n",
      "dtypes: float64(154), int64(1), object(2)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "features_df.select_dtypes(include = ['float64']).info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8128 entries, 0 to 8127\n",
      "Columns: 154 entries, loudness to vect_148\n",
      "dtypes: float64(154)\n",
      "memory usage: 9.5 MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "features_df.select_dtypes(include = ['int64']).info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8128 entries, 0 to 8127\n",
      "Data columns (total 1 columns):\n",
      " #   Column   Non-Null Count  Dtype\n",
      "---  ------   --------------  -----\n",
      " 0   trackID  8128 non-null   int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 63.6 KB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "numeric_feat = features_df.select_dtypes(include = ['float64']).columns\n",
    "int_feat = features_df.select_dtypes(include = ['int64']).columns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# convert data type of numeric columns in features_df to float16. quantization \n",
    "# convert id col to int16 instead of int8 to preserve data integrity\n",
    "features_df[numeric_feat] = features_df[numeric_feat].astype(np.float16)\n",
    "features_df[int_feat] = features_df[int_feat].astype(np.int16)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "features_df['trackID'].values == features_df_raw['trackID'].values"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ True,  True,  True, ...,  True,  True,  True])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "all(True for element in features_df['trackID'].values == features_df_raw['trackID'].values)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "features_df.loc[features_df['title'].isnull(), 'tags']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1960    i, the, you, to, and, a, me, it, not, in, my, ...\n",
       "6000    i, the, you, to, and, a, me, it, not, in, is, ...\n",
       "6624    i, the, you, to, and, a, me, it, not, in, is, ...\n",
       "6895    i, the, you, to, and, a, it, not, in, is, your...\n",
       "6957    i, the, you, to, and, a, me, it, not, in, my, ...\n",
       "7774    i, the, you, to, and, a, it, not, in, my, of, ...\n",
       "7820    i, the, you, to, and, a, it, in, my, is, of, y...\n",
       "Name: tags, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "features_df.loc[features_df['tags'].isnull(), 'title']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "752                             How Many Times\n",
       "1348                                Thou Swell\n",
       "1770                                      Fame\n",
       "2594          Feeding The Mouth That Bites You\n",
       "2792                 She Wakes When She Dreams\n",
       "3872    Hollywood Liar (2004 Digital Remaster)\n",
       "4955            Haven't You Heard (LP Version)\n",
       "5389                            Morbid reality\n",
       "6704                              Celtic Tiger\n",
       "6761                             I Told You So\n",
       "6915                       Black Is The Colour\n",
       "8107                                Strip Song\n",
       "Name: title, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "to investigate whether i, the, you, to, and, a, me, are common words in `tags`. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# fill empty tags with `unk`\n",
    "features_df.loc[features_df['tags'].isnull(), 'tags'] = 'unk'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "features_df['tags'].isnull().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "Counter(\" \".join(features_df[\"tags\"]).split()).most_common(10)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('the,', 6901),\n",
       " ('to,', 6546),\n",
       " ('a,', 6521),\n",
       " ('and,', 6424),\n",
       " ('i,', 6196),\n",
       " ('you,', 5949),\n",
       " ('in,', 5734),\n",
       " ('is,', 5488),\n",
       " ('it,', 5328),\n",
       " ('me,', 5267)]"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "n = 10\n",
    "n_freq_words_in_tags = [word for word in Counter(\" \".join(features_df[\"tags\"]).split()).most_common(n)]\n",
    "n_freq_words_in_tags"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('the,', 6901),\n",
       " ('to,', 6546),\n",
       " ('a,', 6521),\n",
       " ('and,', 6424),\n",
       " ('i,', 6196),\n",
       " ('you,', 5949),\n",
       " ('in,', 5734),\n",
       " ('is,', 5488),\n",
       " ('it,', 5328),\n",
       " ('me,', 5267)]"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# find % that each word in freq words appear in data\n",
    "for word in n_freq_words:\n",
    "    print(word, len(features_df[features_df['tags'].str.contains(word)])/len(features_df) * 100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "the, 84.90403543307087\n",
      "to, 85.17470472440945\n",
      "a, 89.64074803149606\n",
      "and, 82.08661417322834\n",
      "i, 95.3371062992126\n",
      "you, 73.19143700787401\n",
      "in, 83.53838582677166\n",
      "is, 78.56791338582677\n",
      "it, 73.74507874015748\n",
      "me, 85.8267716535433\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# treat words that appear > 80% of the time as stopwords\n",
    "# i create my own list of stopwords so as to avoid removing words that are part of nltk's stopwords \n",
    "# but are considered 'impt' in this use case"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "source": [
    "stopwords_list = []\n",
    "for word in n_freq_words_in_tags:\n",
    "    word = word[0].strip(',')\n",
    "    if len(features_df[features_df['tags'].str.contains(word)])/len(features_df) * 100 > 80:\n",
    "        stopwords_list.append(word)\n",
    "stopwords_list"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['the', 'to', 'a', 'and', 'i', 'in', 'is', 'it', 'me']"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "features_df['tokenized_title'] = features_df['title'].apply(lambda x:utils_preprocess_text(x))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# fill empty title with `unk`\n",
    "features_df.loc[features_df['tokenized_title'].isnull(), 'tokenized_title'] = 'unk'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "n_freq_words_in_title = [word[0] for word in Counter(\" \".join(features_df[\"tokenized_title\"]).split()).most_common(n)]\n",
    "n_freq_words_in_title"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['the,', 'version', 'of,', 'lp,', 'album,', 'a,', 'i,', 'to,', 'you,', 'in,']"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# find % that each word in freq words appear in data\n",
    "for word in n_freq_words_in_title:\n",
    "    print(word, len(features_df[features_df['tokenized_title'].str.contains(word)])/len(features_df) * 100)\n",
    "# since these words don't appear frequently, won't remove them from title"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "the, 13.324311023622048\n",
      "version 10.593011811023622\n",
      "of, 5.413385826771654\n",
      "lp, 5.241141732283464\n",
      "album, 4.9827755905511815\n",
      "a, 9.104330708661418\n",
      "i, 5.130413385826771\n",
      "to, 4.416830708661417\n",
      "you, 3.5063976377952755\n",
      "in, 5.3641732283464565\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "since there are missing values for `title` and `tags`, but there are values for `titles` when `tags` are missing and vice versa, i'll concatenate `title` and `tags` as 1 attribute `title_and_tags`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "features_df['tags_clean'] = features_df['tags'].apply(lambda x:utils_preprocess_text(x, lst_stopwords=stopwords_list))\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "source": [
    "features_df[['tags', 'tags_clean']].sample(10, random_state = seed)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                   tags  \\\n",
       "186   i, the, you, to, a, me, it, not, my, is, of, y...   \n",
       "1435  i, the, to, and, a, me, not, in, my, is, of, t...   \n",
       "4691  i, you, and, a, me, it, in, my, your, on, are,...   \n",
       "4366  i, the, you, to, and, a, in, my, of, your, tha...   \n",
       "2762  i, the, you, to, and, a, me, it, not, is, of, ...   \n",
       "1969  i, the, you, to, and, a, it, not, in, is, of, ...   \n",
       "4426  i, the, you, and, a, me, not, that, do, are, a...   \n",
       "2134  i, the, you, to, and, a, me, it, not, in, my, ...   \n",
       "2367  i, the, you, to, and, a, me, not, your, do, on...   \n",
       "5625  i, the, you, to, and, of, do, on, are, will, b...   \n",
       "\n",
       "                                             tags_clean  \n",
       "186   you, not, my, of, your, that, do, on, are, we,...  \n",
       "1435  not, my, of, that, on, am, will, for, be, so, ...  \n",
       "4691  you, my, your, on, are, will, for, be, love, s...  \n",
       "4366  you, my, of, your, that, do, on, are, we, am, ...  \n",
       "2762  you, not, of, your, that, do, on, are, we, am,...  \n",
       "1969  you, not, of, that, do, are, we, all, be, have...  \n",
       "4426  you, not, that, do, are, am, will, be, what, t...  \n",
       "2134  you, not, my, of, do, on, are, we, all, for, n...  \n",
       "2367  you, not, your, do, on, am, will, all, for, no...  \n",
       "5625  you, of, do, on, are, will, but, what, just, o...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tags</th>\n",
       "      <th>tags_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>i, the, you, to, a, me, it, not, my, is, of, y...</td>\n",
       "      <td>you, not, my, of, your, that, do, on, are, we,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>i, the, to, and, a, me, not, in, my, is, of, t...</td>\n",
       "      <td>not, my, of, that, on, am, will, for, be, so, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4691</th>\n",
       "      <td>i, you, and, a, me, it, in, my, your, on, are,...</td>\n",
       "      <td>you, my, your, on, are, will, for, be, love, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4366</th>\n",
       "      <td>i, the, you, to, and, a, in, my, of, your, tha...</td>\n",
       "      <td>you, my, of, your, that, do, on, are, we, am, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2762</th>\n",
       "      <td>i, the, you, to, and, a, me, it, not, is, of, ...</td>\n",
       "      <td>you, not, of, your, that, do, on, are, we, am,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>i, the, you, to, and, a, it, not, in, is, of, ...</td>\n",
       "      <td>you, not, of, that, do, are, we, all, be, have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426</th>\n",
       "      <td>i, the, you, and, a, me, not, that, do, are, a...</td>\n",
       "      <td>you, not, that, do, are, am, will, be, what, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>i, the, you, to, and, a, me, it, not, in, my, ...</td>\n",
       "      <td>you, not, my, of, do, on, are, we, all, for, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2367</th>\n",
       "      <td>i, the, you, to, and, a, me, not, your, do, on...</td>\n",
       "      <td>you, not, your, do, on, am, will, all, for, no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5625</th>\n",
       "      <td>i, the, you, to, and, of, do, on, are, will, b...</td>\n",
       "      <td>you, of, do, on, are, will, but, what, just, o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "source": [
    "features_df['title_and_tags'] = features_df['tokenized_title'] + ', ' + features_df['tags_clean']\n",
    "# check for nulls\n",
    "features_df['title_and_tags'].isnull().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "corpus = features_df['title_and_tags'].astype(str)\n",
    "TFidf = TfidfVectorizer(strip_accents = 'unicode', \n",
    "#                      stop_words = 'english',\n",
    "                     lowercase = True,\n",
    "                     analyzer = 'word',\n",
    "                     token_pattern = r'\\b[a-zA-Z]{3,}\\b',\n",
    "                     max_df = 0.7, \n",
    "                     min_df = 10, \n",
    "                     ngram_range=(1,2)) \n",
    "dtm_TFidf = TFidf.fit_transform(corpus)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "source": [
    "dtm_TFidf.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8128, 10250)"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "source": [
    "# convert document-term matrix into a df so that we can combine with original df\n",
    "# add `d_` prefix as an identifier for easier filtering later \n",
    "title_and_tags_label = [e[:30]+\"...\" for e in corpus]\n",
    "dtm_TFidf_df = pd.DataFrame(dtm_TFidf.toarray(), index=title_and_tags_label, columns=[\"d_\" + str(i) for i in TFidf.get_feature_names()])\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "# quantize values\n",
    "dtm_TFidf_df = dtm_TFidf_df.astype(np.float16)\n",
    "dtm_TFidf_df.info()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8128 entries, beside, the, yellow, line, not... to whenever, youre, ready, you, n...\n",
      "Columns: 10250 entries, d_aah to d_zwei\n",
      "dtypes: float16(10250)\n",
      "memory usage: 159.0+ MB\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "numeric_feat_and_id = list(int_feat) + list(numeric_feat)\n",
    "len(numeric_feat_and_id) == len(list(int_feat)) + len(list(numeric_feat))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "features_df[numeric_feat_and_id].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8128, 155)"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "# combine dtm_TFidf_df with original df\n",
    "dtm_TFidf_df['trackID'] = features_df['trackID'].values\n",
    "features_df1 = features_df[numeric_feat_and_id].merge(dtm_TFidf_df, on = 'trackID')\n",
    "features_df1.head(2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   trackID  loudness     tempo  time_signature  key  mode  duration    vect_1  \\\n",
       "0     6654 -8.539062  104.3125             3.0  7.0   1.0   298.750  44.46875   \n",
       "1     5883 -4.324219  142.0000             3.0  6.0   0.0   236.125  46.06250   \n",
       "\n",
       "      vect_2  vect_3  ...  d_youth  d_yuh  d_zeit  d_zero  d_zone  d_zoo  \\\n",
       "0 -13.500000  26.250  ...      0.0    0.0     0.0     0.0     0.0    0.0   \n",
       "1  16.984375  -1.875  ...      0.0    0.0     0.0     0.0     0.0    0.0   \n",
       "\n",
       "   d_zum  d_zur  d_zuruck  d_zwei  \n",
       "0    0.0    0.0       0.0     0.0  \n",
       "1    0.0    0.0       0.0     0.0  \n",
       "\n",
       "[2 rows x 10405 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trackID</th>\n",
       "      <th>loudness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>duration</th>\n",
       "      <th>vect_1</th>\n",
       "      <th>vect_2</th>\n",
       "      <th>vect_3</th>\n",
       "      <th>...</th>\n",
       "      <th>d_youth</th>\n",
       "      <th>d_yuh</th>\n",
       "      <th>d_zeit</th>\n",
       "      <th>d_zero</th>\n",
       "      <th>d_zone</th>\n",
       "      <th>d_zoo</th>\n",
       "      <th>d_zum</th>\n",
       "      <th>d_zur</th>\n",
       "      <th>d_zuruck</th>\n",
       "      <th>d_zwei</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6654</td>\n",
       "      <td>-8.539062</td>\n",
       "      <td>104.3125</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>298.750</td>\n",
       "      <td>44.46875</td>\n",
       "      <td>-13.500000</td>\n",
       "      <td>26.250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5883</td>\n",
       "      <td>-4.324219</td>\n",
       "      <td>142.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>236.125</td>\n",
       "      <td>46.06250</td>\n",
       "      <td>16.984375</td>\n",
       "      <td>-1.875</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 10405 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "source": [
    "features_df1.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8128, 10405)"
      ]
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "vect_cols = [col for col in features_df1.columns if col.startswith('vect')]\n",
    "len(vect_cols)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "tfidf_cols = [col for col in features_df1.columns if col.startswith('d_')]\n",
    "len(tfidf_cols)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10250"
      ]
     },
     "metadata": {},
     "execution_count": 100
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}